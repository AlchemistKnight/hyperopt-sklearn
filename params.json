{"name":"Hyperopt-sklearn","tagline":"Hyper-parameter optimization for sklearn","body":"### Work In Progress...\r\n\r\n### Usage\r\n\r\n```python\r\nfrom hpsklearn import hyperopt_estimator\r\n\r\n# Load Data\r\n# ...\r\n\r\n# Create the estimator object\r\nestim = hyperopt_estimator()\r\n\r\n# Search the space of classifiers and preprocessing steps and their\r\n# respective hyperparameters in sklearn to fit a model to the data\r\nestim.fit( train_data, train_label )\r\n\r\n# Make a prediction using the optimized model\r\nprediction = estim.predict( unknown_data )\r\n\r\n# Report the accuracy of the classifier on a given set of data\r\nscore = estim.score( test_data, test_label )\r\n\r\n# Return instances of the classifier and preprocessing steps used in the optimized model\r\nmodel = estim.best_model()\r\n```\r\n\r\n### Search Algorithms\r\n\r\nAny search algorithm available in hyperopt can be used to drive the estimator. It is also possible to supply your own or use a mix of algorithms. The number of points to evaluate before returning, as well as an optional timeout (in seconds) can be used with any search algorithm. \r\n\r\n```python\r\nfrom hyperopt import tpe\r\n\r\nestim = hyperopt_estimator( algo=tpe.suggest, max_evals=150, trial_timeout=60 )\r\n```\r\n\r\nSearch algorithms available so far:\r\n\r\n* Random Search\r\n* Tree of Parzen Estimators (TPE)\r\n* Annealing\r\n* Tree\r\n* Gaussian Process Tree\r\n\r\n### Classifiers\r\n\r\n<<Small example of importing and using classifier>>\r\n\r\n\r\n\r\nClassifiers from sklearn that are built-in so far:\r\n\r\n* SVC\r\n* LinearSVC\r\n* KNeightborsClassifier\r\n* RandomForestClassifier\r\n* ExtraTreesClassifier\r\n* SGDClassifier\r\n* MultinomialNB\r\n* #BernoulliRBM\r\n* #ColumnKMeans\r\n\r\nMore to come!\r\n\r\n### Preprocessing\r\n\r\n<<Small example of importing and using two preprocessing steps>>\r\n\r\nPreprocessing steps from sklearn that are built-in so far:\r\n\r\n* PCA\r\n* TfidfVectorizer\r\n* StandardScalar\r\n* MinMaxScalar\r\n* Normalizer\r\n* OneHotEncoder\r\n\r\n\r\nMore to come!\r\n\r\n### Installation\r\n\r\n```\r\ngit clone https://github.com/hyperopt/hyperopt-sklearn.git\r\ncd hyperopt\r\npip install -e .\r\n```\r\n\r\n### Documentation\r\n\r\n\r\n### Examples\r\n\r\nAn example on the MNIST digit data\r\n\r\n```python\r\nfrom hpsklearn import hyperopt_estimator, any_classifier\r\nfrom sklearn.datasets import fetch_mldata\r\nfrom hyperopt import tpe\r\nimport numpy as np\r\n\r\n# Download the data and split into training and test sets\r\n\r\ndigits = fetch_mldata('MNIST original')\r\n\r\nX = digits.data\r\ny = digits.target\r\n\r\ntest_size = int( 0.2 * len( y ) )\r\nnp.random.seed( seed )\r\nindices = np.random.permutation(len(X))\r\nX_train = X[ indices[:-test_size]]\r\ny_train = y[ indices[:-test_size]]\r\nX_test = X[ indices[-test_size:]]\r\ny_test = y[ indices[-test_size:]]\r\n\r\nestim = hyperopt_estimator( classifier=any_classifier('clf'),  \r\n                            algo=tpe.suggest, trial_timeout=300)\r\n\r\nestim.fit( X_train, y_train )\r\n\r\nprint( estim.score( X_test, y_test ) )\r\n# <<show score here>>\r\nprint( estim.best_model() )\r\n# <<show model here>>\r\n```\r\n\r\nNot all classifiers within sklearn support sparse data. To make life easier, hpsklearn comes with an any_sparse_classifier which will only sample from the classifiers available which accept sparse data.\r\n\r\n\r\n```python\r\nfrom hpsklearn import hyperopt_estimator, any_sparse_classifier, tfidf\r\nfrom sklearn.datasets import fetch_20newsgroups\r\nfrom sklearn import metrics\r\nfrom hyperopt import tpe\r\nimport numpy as np\r\n\r\n# Download the data and split into training and test sets\r\n\r\ntrain = fetch_20newsgroups( subset='train' )\r\ntest = fetch_20newsgroups( subset='test' )\r\nX_train = train.data\r\ny_train = train.target\r\nX_test = test.data\r\ny_test = test.target\r\n\r\nestim = hyperopt_estimator( classifier=any_sparse_classifier('clf'), \r\n                            preprocessing=[tfidf('tfidf')],\r\n                            algo=tpe.suggest, trial_timeout=300)\r\n\r\nestim.fit( X_train, y_train )\r\n\r\nprint( estim.score( X_test, y_test ) )\r\n# <<show score here>>\r\nprint( estim.best_model() )\r\n# <<show model here>>\r\n```","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}