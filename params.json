{"name":"Hyperopt-sklearn","tagline":"Hyper-parameter optimization for sklearn","body":"### Work In Progress...\r\n\r\n### Usage\r\n\r\n\r\n\r\n### Search Algorithms\r\n\r\n\r\n### Classifiers\r\n\r\nClassifiers from sklearn that are built-in so far:\r\n\r\n* SVC\r\n* LinearSVC\r\n* KNeightborsClassifier\r\n* RandomForestClassifier\r\n* ExtraTreesClassifier\r\n* SGDClassifier\r\n* MultinomialNB\r\n* #BernoulliRBM\r\n* #ColumnKMeans\r\n\r\nMore to come!\r\n\r\n### Preprocessing\r\n\r\nPreprocessing steps from sklearn that are built-in so far:\r\n\r\n* PCA\r\n* TfidfVectorizer\r\n* StandardScalar\r\n* MinMaxScalar\r\n* Normalizer\r\n* OneHotEncoder\r\n\r\n\r\nMore to come!\r\n\r\n### Installation\r\n\r\n\r\n### Documentation\r\n\r\n\r\n### Examples\r\n\r\nAn example on the MNIST digit data\r\n\r\n```python\r\nfrom hpsklearn import hyperopt_estimator, any_classifier\r\nfrom sklearn.datasets import fetch_mldata\r\nfrom sklearn import metrics\r\nfrom hyperopt import tpe\r\nimport numpy as np\r\n\r\n# Download the data and split into training and test sets\r\n\r\ndigits = fetch_mldata('MNIST original')\r\n\r\nX = digits.data\r\ny = digits.target\r\n\r\ntest_size = int( 0.2 * len( y ) )\r\nnp.random.seed( seed )\r\nindices = np.random.permutation(len(X))\r\nX_train = X[ indices[:-test_size]]\r\ny_train = y[ indices[:-test_size]]\r\nX_test = X[ indices[-test_size:]]\r\ny_test = y[ indices[-test_size:]]\r\n\r\nestim = hyperopt_estimator( classifier=any_classifier('clf'),  \r\n                            algo=tpe.suggest, trial_timeout=300)\r\n\r\nestim.fit( X_train, y_train )\r\n\r\npred = estim.predict( X_test )\r\n\r\nprint( metrics.f1_score( pred, y_test ) )\r\n# <<show score here>>\r\nprint( estim.best_model() )\r\n# <<show model here>>\r\n```\r\n\r\nNot all classifiers within sklearn support sparse data. To make life easier, hpsklearn comes with an any_sparse_classifier which will only sample from the classifiers available which accept sparse data.\r\n\r\n\r\n```python\r\nfrom hpsklearn import hyperopt_estimator, any_sparse_classifier, tfidf\r\nfrom sklearn.datasets import fetch_20newsgroups\r\nfrom sklearn import metrics\r\nfrom hyperopt import tpe\r\nimport numpy as np\r\n\r\n# Download the data and split into training and test sets\r\n\r\ntrain = fetch_20newsgroups( subset='train' )\r\ntest = fetch_20newsgroups( subset='test' )\r\nX_train = train.data\r\ny_train = train.target\r\nX_test = test.data\r\ny_test = test.target\r\n\r\nestim = hyperopt_estimator( classifier=any_sparse_classifier('clf'),  \r\n                            preprocessing=[tfidf('tfidf')], \r\n                            algo=tpe.suggest, trial_timeout=300)\r\n\r\nestim.fit( X_train, y_train )\r\n\r\npred = estim.predict( X_test )\r\n\r\nprint( metrics.f1_score( pred, y_test ) )\r\n# <<show score here>>\r\nprint( estim.best_model() )\r\n# <<show model here>>\r\n```","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}