<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Hyperopt-sklearn by bjkomer</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/main.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>

      <header>
        <h1>Hyperopt-sklearn</h1>
        <p>Hyper-parameter optimization for sklearn</p>
      </header>

      <div id="banner">
        <span id="logo"></span>

        <a href="https://github.com/bjkomer/hyperopt-sklearn" class="button fork"><strong>View On GitHub</strong></a>
        <div class="downloads">
          <span>Downloads:</span>
          <ul>
            <li><a href="https://github.com/bjkomer/hyperopt-sklearn/zipball/master" class="button">ZIP</a></li>
            <li><a href="https://github.com/bjkomer/hyperopt-sklearn/tarball/master" class="button">TAR</a></li>
          </ul>
        </div>
      </div><!-- end banner -->

    <div class="wrapper">
      <nav>
        <ul></ul>
      </nav>
      <section>
        <h2>
<a name="what-is-hyperopt-sklearn" class="anchor" href="#what-is-hyperopt-sklearn"><span class="octicon octicon-link"></span></a>What is Hyperopt-sklearn?</h2>

<p>Finding the right classifier to use for your data can be hard. Once you have chosen a classifier, tuning all of the parameters to get the best results is tedious and time consuming. Even after all of your hard work, you may have chosen the wrong classifier to begin with. Hyperopt-sklearn provides a solution to this problem.</p>

<h2>
<a name="usage" class="anchor" href="#usage"><span class="octicon octicon-link"></span></a>Usage</h2>

<div class="highlight highlight-python"><pre><span class="kn">from</span> <span class="nn">hpsklearn</span> <span class="kn">import</span> <span class="n">hyperopt_estimator</span>

<span class="c"># Load Data</span>
<span class="c"># ...</span>

<span class="c"># Create the estimator object</span>
<span class="n">estim</span> <span class="o">=</span> <span class="n">hyperopt_estimator</span><span class="p">()</span>

<span class="c"># Search the space of classifiers and preprocessing steps and their</span>
<span class="c"># respective hyperparameters in sklearn to fit a model to the data</span>
<span class="n">estim</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">train_label</span> <span class="p">)</span>

<span class="c"># Make a prediction using the optimized model</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">estim</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span> <span class="n">unknown_data</span> <span class="p">)</span>

<span class="c"># Report the accuracy of the classifier on a given set of data</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">estim</span><span class="o">.</span><span class="n">score</span><span class="p">(</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">test_label</span> <span class="p">)</span>

<span class="c"># Return instances of the classifier and preprocessing steps</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">estim</span><span class="o">.</span><span class="n">best_model</span><span class="p">()</span>
</pre></div>

<h2>
<a name="search-algorithms" class="anchor" href="#search-algorithms"><span class="octicon octicon-link"></span></a>Search Algorithms</h2>

<p>Any search algorithm available in hyperopt can be used to drive the estimator. It is also possible to supply your own or use a mix of algorithms. The number of points to evaluate before returning, as well as an optional timeout (in seconds) can be used with any search algorithm. </p>

<div class="highlight highlight-python"><pre><span class="kn">from</span> <span class="nn">hpsklearn</span> <span class="kn">import</span> <span class="n">hyperopt_estimator</span>
<span class="kn">from</span> <span class="nn">hyperopt</span> <span class="kn">import</span> <span class="n">tpe</span>

<span class="n">estim</span> <span class="o">=</span> <span class="n">hyperopt_estimator</span><span class="p">(</span> <span class="n">algo</span><span class="o">=</span><span class="n">tpe</span><span class="o">.</span><span class="n">suggest</span><span class="p">,</span> 
                            <span class="n">max_evals</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> 
                            <span class="n">trial_timeout</span><span class="o">=</span><span class="mi">60</span> <span class="p">)</span>
</pre></div>

<p>Search algorithms available so far:</p>

<ul>
<li>Random Search</li>
<li>Tree of Parzen Estimators (TPE)</li>
<li>Annealing</li>
<li>Tree</li>
<li>Gaussian Process Tree</li>
</ul><h2>
<a name="classifiers" class="anchor" href="#classifiers"><span class="octicon octicon-link"></span></a>Classifiers</h2>

<p>If you know what type of classifier you wish to use on your dataset, you can let hpsklearn know and it will only search in the parameter space of the given classifier.</p>

<div class="highlight highlight-python"><pre><span class="kn">from</span> <span class="nn">hpsklearn</span> <span class="kn">import</span> <span class="n">hyperopt_estimator</span><span class="p">,</span> <span class="n">svc</span>

<span class="n">estim</span> <span class="o">=</span> <span class="n">hyperopt_estimator</span><span class="p">(</span> <span class="n">classifier</span><span class="o">=</span><span class="n">svc</span><span class="p">(</span><span class="s">'mySVC'</span><span class="p">)</span> <span class="p">)</span>
</pre></div>

<p>You can also provide sets of classifiers, and optionally choose the probability of the estimator picking each one.</p>

<div class="highlight highlight-python"><pre><span class="kn">from</span> <span class="nn">hpsklearn</span> <span class="kn">import</span> <span class="n">hyperopt_estimator</span><span class="p">,</span> <span class="n">random_forest</span><span class="p">,</span> <span class="n">svc</span><span class="p">,</span> <span class="n">knn</span>
<span class="kn">from</span> <span class="nn">hyperopt</span> <span class="kn">import</span> <span class="n">hp</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">pchoice</span><span class="p">(</span> <span class="s">'my_name'</span><span class="p">,</span> 
          <span class="p">[</span> <span class="p">(</span> <span class="mf">0.4</span><span class="p">,</span> <span class="n">random_forest</span><span class="p">(</span><span class="s">'my_name.random_forest'</span><span class="p">)</span> <span class="p">),</span>
            <span class="p">(</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">svc</span><span class="p">(</span><span class="s">'my_name.svc'</span><span class="p">)</span> <span class="p">),</span>
            <span class="p">(</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">knn</span><span class="p">(</span><span class="s">'my_name.knn'</span><span class="p">)</span> <span class="p">)</span> <span class="p">]</span>

<span class="n">estim</span> <span class="o">=</span> <span class="n">hyperopt_estimator</span><span class="p">(</span> <span class="n">classifier</span><span class="o">=</span><span class="n">clf</span> <span class="p">)</span>
</pre></div>

<p>Classifiers from sklearn that are built-in so far:</p>

<ul>
<li>SVC</li>
<li>LinearSVC</li>
<li>KNeightborsClassifier</li>
<li>RandomForestClassifier</li>
<li>ExtraTreesClassifier</li>
<li>SGDClassifier</li>
<li>MultinomialNB</li>
<li>BernoulliRBM</li>
<li>ColumnKMeans</li>
</ul><p>More to come!</p>

<h2>
<a name="preprocessing" class="anchor" href="#preprocessing"><span class="octicon octicon-link"></span></a>Preprocessing</h2>

<p>You also have control over which preprocessing steps are applied to your data. These can be passed as a list to the hyperopt_estimator. A blank list indicates no preprocessing will be done.</p>

<div class="highlight highlight-python"><pre><span class="kn">from</span> <span class="nn">hpsklearn</span> <span class="kn">import</span> <span class="n">hyperopt_estimator</span><span class="p">,</span> <span class="n">pca</span>

<span class="n">estim</span> <span class="o">=</span> <span class="n">hyperopt_estimator</span><span class="p">(</span> <span class="n">preprocessing</span><span class="o">=</span><span class="p">[</span> <span class="n">pca</span><span class="p">(</span><span class="s">'my_pca'</span><span class="p">)</span> <span class="p">]</span> <span class="p">)</span>
</pre></div>

<p>Preprocessing steps from sklearn that are built-in so far:</p>

<ul>
<li>PCA</li>
<li>TfidfVectorizer</li>
<li>StandardScalar</li>
<li>MinMaxScalar</li>
<li>Normalizer</li>
<li>OneHotEncoder</li>
</ul><p>More to come!</p>

<h2>
<a name="installation" class="anchor" href="#installation"><span class="octicon octicon-link"></span></a>Installation</h2>

<pre><code>git clone https://github.com/hyperopt/hyperopt-sklearn.git
cd hyperopt
pip install -e .
</code></pre>

<h2>
<a name="documentation" class="anchor" href="#documentation"><span class="octicon octicon-link"></span></a>Documentation</h2>

<p>Documentation coming soon. </p>

<p>This project is built upon:</p>

<ul>
<li><a href="http://hyperopt.github.io/hyperopt/">hyperopt</a></li>
<li><a href="http://scikit-learn.org/">scikit-learn</a></li>
</ul><h2>
<a name="examples" class="anchor" href="#examples"><span class="octicon octicon-link"></span></a>Examples</h2>

<p>An example on the MNIST digit data</p>

<div class="highlight highlight-python"><pre><span class="kn">from</span> <span class="nn">hpsklearn</span> <span class="kn">import</span> <span class="n">hyperopt_estimator</span><span class="p">,</span> <span class="n">any_classifier</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_mldata</span>
<span class="kn">from</span> <span class="nn">hyperopt</span> <span class="kn">import</span> <span class="n">tpe</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="c"># Download the data and split into training and test sets</span>

<span class="n">digits</span> <span class="o">=</span> <span class="n">fetch_mldata</span><span class="p">(</span><span class="s">'MNIST original'</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span>

<span class="n">test_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span> <span class="n">y</span> <span class="p">)</span> <span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span> <span class="n">seed</span> <span class="p">)</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span> <span class="n">indices</span><span class="p">[:</span><span class="o">-</span><span class="n">test_size</span><span class="p">]]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span> <span class="n">indices</span><span class="p">[:</span><span class="o">-</span><span class="n">test_size</span><span class="p">]]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span> <span class="n">indices</span><span class="p">[</span><span class="o">-</span><span class="n">test_size</span><span class="p">:]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span> <span class="n">indices</span><span class="p">[</span><span class="o">-</span><span class="n">test_size</span><span class="p">:]]</span>

<span class="n">estim</span> <span class="o">=</span> <span class="n">hyperopt_estimator</span><span class="p">(</span> <span class="n">classifier</span><span class="o">=</span><span class="n">any_classifier</span><span class="p">(</span><span class="s">'clf'</span><span class="p">),</span>  
                            <span class="n">algo</span><span class="o">=</span><span class="n">tpe</span><span class="o">.</span><span class="n">suggest</span><span class="p">,</span> <span class="n">trial_timeout</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>

<span class="n">estim</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="p">)</span>

<span class="k">print</span><span class="p">(</span> <span class="n">estim</span><span class="o">.</span><span class="n">score</span><span class="p">(</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="p">)</span> <span class="p">)</span>
<span class="c"># &lt;&lt;show score here&gt;&gt;</span>
<span class="k">print</span><span class="p">(</span> <span class="n">estim</span><span class="o">.</span><span class="n">best_model</span><span class="p">()</span> <span class="p">)</span>
<span class="c"># &lt;&lt;show model here&gt;&gt;</span>
</pre></div>

<p>Not all classifiers within sklearn support sparse data. To make life easier, hpsklearn comes with an any_sparse_classifier which will only sample from the classifiers available which accept sparse data.</p>

<div class="highlight highlight-python"><pre><span class="kn">from</span> <span class="nn">hpsklearn</span> <span class="kn">import</span> <span class="n">hyperopt_estimator</span><span class="p">,</span> <span class="n">any_sparse_classifier</span><span class="p">,</span> <span class="n">tfidf</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">hyperopt</span> <span class="kn">import</span> <span class="n">tpe</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="c"># Download the data and split into training and test sets</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span> <span class="n">subset</span><span class="o">=</span><span class="s">'train'</span> <span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span> <span class="n">subset</span><span class="o">=</span><span class="s">'test'</span> <span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">data</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">target</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">data</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">target</span>

<span class="n">estim</span> <span class="o">=</span> <span class="n">hyperopt_estimator</span><span class="p">(</span> <span class="n">classifier</span><span class="o">=</span><span class="n">any_sparse_classifier</span><span class="p">(</span><span class="s">'clf'</span><span class="p">),</span> 
                            <span class="n">preprocessing</span><span class="o">=</span><span class="p">[</span><span class="n">tfidf</span><span class="p">(</span><span class="s">'tfidf'</span><span class="p">)],</span>
                            <span class="n">algo</span><span class="o">=</span><span class="n">tpe</span><span class="o">.</span><span class="n">suggest</span><span class="p">,</span> <span class="n">trial_timeout</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>

<span class="n">estim</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="p">)</span>

<span class="k">print</span><span class="p">(</span> <span class="n">estim</span><span class="o">.</span><span class="n">score</span><span class="p">(</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="p">)</span> <span class="p">)</span>
<span class="c"># &lt;&lt;show score here&gt;&gt;</span>
<span class="k">print</span><span class="p">(</span> <span class="n">estim</span><span class="o">.</span><span class="n">best_model</span><span class="p">()</span> <span class="p">)</span>
<span class="c"># &lt;&lt;show model here&gt;&gt;</span>
</pre></div>

<h2>
<a name="empirical-results" class="anchor" href="#empirical-results"><span class="octicon octicon-link"></span></a>Empirical Results</h2>

<h3>
<a name="comparison-between-algorithms" class="anchor" href="#comparison-between-algorithms"><span class="octicon octicon-link"></span></a>Comparison Between Algorithms</h3>

<p>Tests were run on the 20 newsgroups dataset with 300 evaluations for each algorithm. The set of classifiers available where a support vector machine (SVM), k nearest neighbors (KNeighborsClassifier), naive bayes (MultinomialNB), and stochastic gradient descent (SGDClassifier). TfidfVectorizer was used to perform the preprocessing in all cases.</p>

<p>Each algorithm was run multiple times (between 6 to 9 times) with different random seeds and the results of the validation score after each evaluation was recorded. A linear trend-line was fit to the data in each case, and is overlayed on top of the data in red. The results for TPE and random search are shown below.</p>

<p>[[TODO: plot of TPE goes here]]
[[TODO: plot of Random goes here]]</p>

<p>These are the trend-lines found for each algorithm</p>

<p>[[TODO: plot of results goes here]]</p>

<h3>
<a name="comparison-to-default-parameters" class="anchor" href="#comparison-to-default-parameters"><span class="octicon octicon-link"></span></a>Comparison to Default Parameters</h3>

<p>Examples of using hyperopt-sklearn to pick parameters contrasted with the default parameters chosen by scikit-learn. This demonstrates how much improvement can be obtained with roughly the same amount of code and without any expert domain knowledge required.</p>

<p>[[TODO: example code and table of results goes here]]</p>
      </section>
      <footer>
        <p>Project maintained by <a href="https://github.com/bjkomer">bjkomer</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></small></p>
      </footer>
    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>